{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffq6A2-ifzAA"
   },
   "source": [
    "# Интеллектуальный анализ данных – весна 2025\n",
    "# Домашнее задание 6: классификация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPcxtekTA1Sm"
   },
   "source": [
    "Правила:\n",
    "\n",
    "\n",
    "\n",
    "*   Домашнее задание оценивается в 10 баллов.\n",
    "*   Можно использовать без доказательства любые результаты, встречавшиеся на лекциях или семинарах по курсу, если получение этих результатов не является вопросом задания.\n",
    "*  Можно использовать любые свободные источники с *обязательным* указанием ссылки на них.\n",
    "*  Плагиат не допускается. При обнаружении случаев списывания, 0 за работу выставляется всем участникам нарушения, даже если можно установить, кто у кого списал.\n",
    "*  Старайтесь сделать код как можно более оптимальным. В частности, будет штрафоваться использование циклов в тех случаях, когда операцию можно совершить при помощи инструментов библиотек, о которых рассказывалось в курсе.\n",
    "* Если в задании есть вопрос на рассуждение, то за отсутствие ответа на него балл за задание будет снижен вполовину."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itRtFtrOf0_b"
   },
   "source": [
    "В этом домашнем задании вам предстоит построить классификатор текстов.\n",
    "\n",
    "Будем предсказывать эмоциональную окраску твиттов о коронавирусе.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "tNGRVO7_g9mz"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import  List\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from string import punctuation\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "zOy8iHJQg_Ss",
    "outputId": "6a32c325-1b9a-4895-ab22-5e985016da91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>4755</td>\n",
       "      <td>49707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17-03-2020</td>\n",
       "      <td>@DuScarla @wanda1606 @CarolineVoaden @Emmanuel...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9108</th>\n",
       "      <td>14855</td>\n",
       "      <td>59807</td>\n",
       "      <td>India</td>\n",
       "      <td>20-03-2020</td>\n",
       "      <td>Breaking Union Minister of Consumer Affairs Fo...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16738</th>\n",
       "      <td>24179</td>\n",
       "      <td>69131</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>25-03-2020</td>\n",
       "      <td>Nice job Stop amp Shop northeastern grocery st...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>7631</td>\n",
       "      <td>52583</td>\n",
       "      <td>Al Hilal - C Ring Road</td>\n",
       "      <td>18-03-2020</td>\n",
       "      <td>#MoCI sets prices for hand #sanitisers, #disin...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                Location     TweetAt  \\\n",
       "796        4755       49707                     NaN  17-03-2020   \n",
       "9108      14855       59807                   India  20-03-2020   \n",
       "16738     24179       69131                Michigan  25-03-2020   \n",
       "3165       7631       52583  Al Hilal - C Ring Road  18-03-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "796    @DuScarla @wanda1606 @CarolineVoaden @Emmanuel...            Negative  \n",
       "9108   Breaking Union Minister of Consumer Affairs Fo...            Positive  \n",
       "16738  Nice job Stop amp Shop northeastern grocery st...  Extremely Negative  \n",
       "3165   #MoCI sets prices for hand #sanitisers, #disin...            Positive  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./tweets_coronavirus.csv', encoding='latin-1')\n",
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2OiDog9ZBlS"
   },
   "source": [
    "Для каждого твитта указано:\n",
    "\n",
    "\n",
    "*   UserName - имя пользователя, заменено на целое число для анонимности\n",
    "*   ScreenName - отображающееся имя пользователя, заменено на целое число для анонимности\n",
    "*   Location - местоположение\n",
    "*   TweetAt - дата создания твитта\n",
    "*   OriginalTweet - текст твитта\n",
    "*   Sentiment - эмоциональная окраска твитта (целевая переменная)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZTMseDkhTC7"
   },
   "source": [
    "## Задание 1 Подготовка (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx2-odn9hdAW"
   },
   "source": [
    "Целевая переменная находится в колонке `Sentiment`.  Преобразуйте ее таким образом, чтобы она стала бинарной: 1 - если у твитта положительная или очень положительная эмоциональная окраска и 0 - если отрицательная или очень отрицательная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3804</td>\n",
       "      <td>48756</td>\n",
       "      <td>ÃÂT: 36.319708,-82.363649</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>As news of the regionÃÂs first confirmed COV...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName                     Location     TweetAt  \\\n",
       "0      3800       48752                           UK  16-03-2020   \n",
       "1      3801       48753                    Vagabonds  16-03-2020   \n",
       "2      3802       48754                          NaN  16-03-2020   \n",
       "3      3803       48755                          NaN  16-03-2020   \n",
       "4      3804       48756  ÃÂT: 36.319708,-82.363649  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  advice Talk to your neighbours family to excha...            Positive  \n",
       "1  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "2  My food stock is not the only one which is emp...            Positive  \n",
       "3  Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
       "4  As news of the regionÃÂs first confirmed COV...            Positive  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# было\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "ZaQKQ1zEjP15"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3804</td>\n",
       "      <td>48756</td>\n",
       "      <td>ÃÂT: 36.319708,-82.363649</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>As news of the regionÃÂs first confirmed COV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName                     Location     TweetAt  \\\n",
       "0      3800       48752                           UK  16-03-2020   \n",
       "1      3801       48753                    Vagabonds  16-03-2020   \n",
       "2      3802       48754                          NaN  16-03-2020   \n",
       "3      3803       48755                          NaN  16-03-2020   \n",
       "4      3804       48756  ÃÂT: 36.319708,-82.363649  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet  Sentiment  \n",
       "0  advice Talk to your neighbours family to excha...          1  \n",
       "1  Coronavirus Australia: Woolworths to give elde...          1  \n",
       "2  My food stock is not the only one which is emp...          1  \n",
       "3  Me, ready to go at supermarket during the #COV...          0  \n",
       "4  As news of the regionÃÂs first confirmed COV...          1  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"] = np.where(df[\"Sentiment\"].str.contains(\"[Pp]ositive\"), 1, 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGq1FxJ-kBo5"
   },
   "source": [
    "Сбалансированы ли классы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "a7gdNtxckK5V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "1    18046\n",
       "0    15398\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_vc = df[\"Sentiment\"].value_counts()\n",
    "sentiment_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.67"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif = np.abs(sentiment_vc.iloc[0] - sentiment_vc.iloc[1]) / np.max([sentiment_vc.iloc[0], sentiment_vc.iloc[1]])\n",
    "np.round(100 * dif, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ng8BCelMkWb0"
   },
   "source": [
    "**Ответ:** разница в $\\thicksim$15% приемлема для принятия отношения\n",
    "классов за сбалансированные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmSIBSsLk5Zz"
   },
   "source": [
    "Выведете на экран информацию о пропусках в данных. Если пропуски присутствуют заполните их строкой 'Unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "UhUVRkR5kxa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName            0\n",
       "ScreenName          0\n",
       "Location         7049\n",
       "TweetAt             0\n",
       "OriginalTweet       0\n",
       "Sentiment           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет данных про локацию, заменим все пустой строкой `unknown`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName         0\n",
       "ScreenName       0\n",
       "Location         0\n",
       "TweetAt          0\n",
       "OriginalTweet    0\n",
       "Sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Location\"] = df[\"Location\"].fillna(\"unknown\")\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tzt27tfjUpq"
   },
   "source": [
    "Разделите данные на обучающие и тестовые в соотношении 7 : 3 и укажите `random_state=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "xSLOA9tIj9Z6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"Sentiment\"]\n",
    "X = df.drop([\"Sentiment\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9RrPUsJlL60"
   },
   "source": [
    "## Задание 2 Токенизация (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Dz_b7Xopc_R"
   },
   "source": [
    "Постройте словарь на основе обучающей выборки и посчитайте количество встреч каждого токена с использованием самой простой токенизации - деления текстов по пробельным символам и приведения токенов в нижний регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "SFr67WOJphny"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30027    None\n",
       "28206    None\n",
       "8905     None\n",
       "11897    None\n",
       "11873    None\n",
       "         ... \n",
       "5238     None\n",
       "3342     None\n",
       "5074     None\n",
       "10512    None\n",
       "19960    None\n",
       "Name: OriginalTweet, Length: 23410, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_data = {}\n",
    "\n",
    "def add_to_words(text_sample):\n",
    "    words = map(lambda x: x.lower(), text_sample.split())\n",
    "    for w in words:\n",
    "        words_data[w] = words_data.get(w, 0) + 1\n",
    "        \n",
    "X_train[\"OriginalTweet\"].apply(add_to_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe0h2Jqkpnao"
   },
   "source": [
    "Какой размер словаря получился?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "umyENA7EpokD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79735"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d2G1Z-Qpqkd"
   },
   "source": [
    "Выведите 10 самых популярных токенов с количеством встреч каждого из них. Объясните, почему именно эти токены в топе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "Impi32a_pssg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the             26682\n",
       "to              23383\n",
       "and             14683\n",
       "of              12857\n",
       "a               11697\n",
       "in              11210\n",
       "for              8519\n",
       "#coronavirus     8243\n",
       "is               7373\n",
       "are              7016\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_data_s = pd.Series(words_data)\n",
    "words_data_s = words_data_s.sort_values(ascending=False)\n",
    "words_data_s.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtuJCD0ApuFd"
   },
   "source": [
    "**Ответ:** Стоп-слова. Стоит заметить, что эти слова не склоняются, и потому их может \n",
    "быть больше, чем, например, склоняемых слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7DTQDkWsVYp"
   },
   "source": [
    "Удалите стоп-слова из словаря и выведите новый топ-10 токенов (и количество встреч) по популярности.  Что можно сказать  о нем?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "8csSAdgTsnFx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#coronavirus    8243\n",
       "prices          3838\n",
       "food            3827\n",
       "grocery         3397\n",
       "supermarket     3325\n",
       "store           3158\n",
       "people          3120\n",
       "covid-19        3069\n",
       "#covid19        2507\n",
       "consumer        2247\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "st_w = stopwords.words(\"english\")\n",
    "\n",
    "new_index_bool = ~np.in1d(words_data_s.index, st_w)\n",
    "new_index = words_data_s.index[new_index_bool]\n",
    "\n",
    "words_data_no_stopwords = words_data_s.reindex(new_index)\n",
    "\n",
    "words_data_no_stopwords.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZH0x2Lzs-Dh"
   },
   "source": [
    "**Ответ:** кроме, собственно, ковида, обсуждается функционирование магазинов \n",
    "и цен: сама основа быта каждого человека. Очевидный вывод: ковид консулся человека настолько плотно, что основные темы для обсуждения - самые низовые потребности, такие как купить покушать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKSGRyI-uor0"
   },
   "source": [
    "Также выведите 20 самых непопулярных слов (если самых непопулярных слов больше, выведите любые 20 из них) Почему эти токены непопулярны, требуется ли как-то дополнительно работать с ними?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "moArbwfvun9t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "https://t.co/f8jjwc6mvb    1\n",
       "https://t.co/x3qrxixl17    1\n",
       "ãâplease                 1\n",
       "kindãâ                   1\n",
       "received!                  1\n",
       "shop-lifting               1\n",
       "https://t.co/k0kgjgjjxu    1\n",
       "1-metre                    1\n",
       "ontarians:                 1\n",
       "??can't                    1\n",
       "??impacted                 1\n",
       "??must                     1\n",
       "yogurt                     1\n",
       "#ontariodairyboard         1\n",
       "https://t.co/ar5uwvvojy    1\n",
       "patrickcobb                1\n",
       "patrick,                   1\n",
       "distancingãâ             1\n",
       "https://t.co/8eamxvsghm    1\n",
       "feared,                    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_data_no_stopwords.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRp3J1gQunlR"
   },
   "source": [
    "**Ответ:** работать с этими токенами не получится, но это не говорит, что, например, \n",
    "токен `prohibitions` (который в топ-20 самых редких) ни о чем не может нам сказать. Просто обработка текста путем сплита по пробелам может дать очень грубые усреднения, на которые можно ориентироваться, только когда ничего другого нет. Этим и займемся..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wx9LQOSPzvjV"
   },
   "source": [
    "Теперь воспользуемся токенайзером получше - TweetTokenizer из библиотеки nltk. Примените его и посмотрите на топ-10 популярных слов. Чем он отличается от топа, который получался раньше? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "2G1UkyVxzvFY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#coronavirus    8819\n",
       "19              7003\n",
       "covid           6087\n",
       "prices          4564\n",
       "food            4378\n",
       "store           3868\n",
       "supermarket     3858\n",
       "grocery         3451\n",
       "people          3422\n",
       "#covid19        2622\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from string import punctuation\n",
    "\n",
    "tokens = {}\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "st_l = st_w + list(punctuation)\n",
    "\n",
    "def parse_tokens(text_sample):\n",
    "    ts = tokenizer.tokenize(text_sample)\n",
    "    for t in ts:\n",
    "        t = t.lower().strip()\n",
    "        if len(t) == 1 and ord(t) >= 128:\n",
    "            continue\n",
    "        if t not in st_l:\n",
    "            tokens[t] = tokens.get(t, 0) + 1\n",
    "\n",
    "X_train[\"OriginalTweet\"].apply(parse_tokens)\n",
    "\n",
    "tokens = pd.Series(tokens).sort_values(ascending=False)\n",
    "tokens.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50eVUnJN1Zxl"
   },
   "source": [
    "**Ответ:** в целом, усреднение по сплиту оказалось полезнее, чем можно было предположить.\n",
    "Топ значений сохранился, как и интерпретация всего этого дела."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gqQgiMs11bs"
   },
   "source": [
    "Удалите из словаря стоп-слова и пунктуацию, посмотрите на новый топ-10 слов с количеством встреч, есть ли теперь в нем что-то не похожее на слова?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "0yHWdFrp0Mup"
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZJqXELP_Yxy"
   },
   "source": [
    "**Ответ:** упс, уже сделал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzXjMsSB_kXB"
   },
   "source": [
    "Скорее всего в некоторых топах были неотображаемые символы или отдельные буквы не латинского алфавита. Уберем их: удалите из словаря токены из одного символа, позиция которого в таблице Unicode 128 и более (`ord(x) >= 128`)\n",
    "\n",
    "Выведите топ-10 самых популярных и топ-20 непопулярных слов. Чем полученные топы отличаются от итоговых топов, полученных при использовании токенизации по пробелам? Что теперь лучше, а что хуже?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "1695hlkS_1-J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vix                        1\n",
       "shootout                   1\n",
       "https://t.co/dufpsf9hxa    1\n",
       "vigilance                  1\n",
       "https://t.co/aq8wnws32l    1\n",
       "@austen                    1\n",
       "https://t.co/xhxtz63vi3    1\n",
       "sudbury                    1\n",
       "@apickrellctv              1\n",
       "https://t.co/arv57dzgns    1\n",
       "https://t.co/buo2a3pald    1\n",
       "brightram                  1\n",
       "@qz                        1\n",
       "rejoin                     1\n",
       "@markneary18               1\n",
       "precludes                  1\n",
       "https://t.co/is6phumisa    1\n",
       "https://t.co/zf0x7ccmzz    1\n",
       "https://t.co/stswfpcjwy    1\n",
       "facade                     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzjHAKIlDvc6"
   },
   "source": [
    "**Ответ:**\n",
    "\n",
    "Изначально я захардкодил пару неинформативных символов, добавив в стоп-лист, но увидев этот пункт изменил решение.\n",
    "\n",
    "Говоря о репрезентативности: топ остался тот же (или почти тот же, но новых выводов сделать нельзя), однако хвост оказался более репрезентативен. Несмотря на теги, ссылки и прочий смысловой мусор, о каких-то токенах мы можем рассуждать как о непопулярных, например, `wrinkles`, `ombudsman` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcDf9_6HB2zm"
   },
   "source": [
    "Выведите топ-10 популярных хештегов (токены, первые символы которых - #) с количеством встреч. Что можно сказать о них?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "zk4fygCUBw3l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#coronavirus            8819\n",
       "#covid19                2622\n",
       "#covid_19               1790\n",
       "#covid2019               971\n",
       "#toiletpaper             728\n",
       "#covid                   641\n",
       "#socialdistancing        492\n",
       "#coronacrisis            437\n",
       "#pandemic                259\n",
       "#coronaviruspandemic     257\n",
       "#stayhome                228\n",
       "#coronavirusoutbreak     224\n",
       "#covid-19                218\n",
       "#stayathome              215\n",
       "#lockdown                215\n",
       "#corona                  212\n",
       "#stayhomesavelives       205\n",
       "#supermarket             200\n",
       "#retail                  191\n",
       "#panicbuying             188\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_pattern = r'^#.+'\n",
    "\n",
    "hashtags_bool = tokens.index.str.match(hashtag_pattern)\n",
    "hashtags_index = tokens.index[hashtags_bool]\n",
    "\n",
    "hashtags = tokens.reindex(hashtags_index)\n",
    "hashtags.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6NeNWBkDxM7"
   },
   "source": [
    "**Ответ:** \n",
    "\n",
    "Выводы похожи на вывод для всех токенов, но с оговоркой. Кроме упоминаний базоых нужд, таких как туалетная бумага и магазины, можно заметить, что хештеги подсвечивают посыл, идею и внутренную ценность автора. Например, `stayhome`, `stayhomesavelives`, `socialdistancing` - явные призывы к действую. Возможно, имеет смысл удеелить хештегам больше внимания при обучении модели.\n",
    "\n",
    "*выбрал топ-20 для большей репрезентативности*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLYBg7caD5GA"
   },
   "source": [
    "То же самое проделайте для ссылок на сайт https://t.co Сравнима ли популярность ссылок с популярностью хештегов? Будет ли информация о ссылке на конкретную страницу полезна?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "MXbm1oeaCK9S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "https://t.co/oxa7swtond    4\n",
       "https://t.co/r7sagojsjg    4\n",
       "https://t.co/ymsemlvttd    3\n",
       "https://t.co/3kfuiojxep    3\n",
       "https://t.co/gu6b4xpqp4    3\n",
       "https://t.co/gp3eusapl8    3\n",
       "https://t.co/pe99mhrsat    3\n",
       "https://t.co/mlw1gfkzna    3\n",
       "https://t.co/catkegayoy    3\n",
       "https://t.co/e2znxajpre    3\n",
       "https://t.co/wrlhyzizaa    3\n",
       "https://t.co/hpo7uwkakl    3\n",
       "https://t.co/jpgmr5hcsc    3\n",
       "https://t.co/7txojqdl04    3\n",
       "https://t.co/g63rp042ho    3\n",
       "https://t.co/6yvykiab2c    3\n",
       "https://t.co/xpcm2xkj4o    3\n",
       "https://t.co/3gbbdpdjat    3\n",
       "https://t.co/2ulz8jrfqw    2\n",
       "https://t.co/pj4ricpwya    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_pattern = r'^https://t\\.co'\n",
    "\n",
    "url_bool = tokens.index.str.match(url_pattern)\n",
    "url_index = tokens.index[url_bool]\n",
    "\n",
    "links = tokens.reindex(url_index)\n",
    "links.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "at6lRYZ8A07N"
   },
   "source": [
    "**Ответ:** самая популярная ссылка имеет 5 твитов с ней, что очень мало. Так что нет, ссылки\n",
    "для анализа не принесут ничего полезного, так как малое количесво данных не может позволить сделать какие-то знаяимые связи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOGdUU1kBU1D"
   },
   "source": [
    "Используем опыт предыдущих экспериментов и напишем собственный токенайзер, улучшив TweetTokenizer. Функция tokenize должна:\n",
    "\n",
    "\n",
    "\n",
    "*   Привести текст в нижний регистр\n",
    "*   Применить TweetTokenizer для  выделения токенов\n",
    "*   Удалить стоп-слова, пунктуацию, токены из одного символа с позицией в таблице Unicode 128 и более,  ссылки на t.co\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "ctEsB6xkFrrK"
   },
   "outputs": [],
   "source": [
    "# не думал не гадал, но уже почти написал его выше\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "st_l = st_w + list(punctuation)\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    tokens = []\n",
    "    ts = tokenizer.tokenize(text)\n",
    "    \n",
    "    for t in ts:\n",
    "        t = t.lower().strip()\n",
    "        \n",
    "        if len(t) == 1 and ord(t) >= 128:\n",
    "            continue\n",
    "        if len(re.findall(url_pattern, t)) > 0:\n",
    "            continue\n",
    "        if t in st_l:\n",
    "            continue\n",
    "\n",
    "        tokens.append(t)\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwbgtYkJGYym",
    "outputId": "5808765b-3448-45e6-ccc1-7cd65f6371ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample', 'text', '@sample_text', '#sampletext']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tokenizer('This is sample text!!!! @Sample_text I, \\x92\\x92 https://t.co  #sampletext')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wURVABmXHk97"
   },
   "source": [
    "## Задание 3 Векторизация текстов (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H44iXkoHIQfN"
   },
   "source": [
    "Обучите CountVectorizer с использованием custom_tokenizer в качестве токенайзера. Как размер полученного словаря соотносится с размером изначального словаря из начала задания 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23410, 5)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHn_limQl3BI",
    "outputId": "8e9c1826-319f-4376-f06e-c30c2eb82648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(tokenizer=custom_tokenizer)\n",
    "cv.fit_transform(X_train[\"OriginalTweet\"])\n",
    "\n",
    "print(len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsfmaSGoItUm"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --\n",
    "\n",
    "было: 45308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lm6UHNmqKZT0"
   },
   "source": [
    "Посмотрим на какой-нибудь конкретный твитт:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "aJVjjfqOJh8m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Shop keepers taking advantage of #Coronavirus boosting prices disproportionately so the most Marginalised suffer who can't afford it #SHAMEONYOU #Wewillremember\",\n",
       " 0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 9023\n",
    "df.iloc[ind]['OriginalTweet'], df.iloc[ind]['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBMIHBI5KdaS"
   },
   "source": [
    "Автор твитта не доволен ситуацией с едой во Франции и текст имеет резко негативную окраску.\n",
    "\n",
    "Примените обученный CountVectorizer для векторизации данного текста, и попытайтесь определить самый важный токен и самый неважный токен (токен, компонента которого в векторе максимальна/минимальна, без учета 0). Хорошо ли они определились, почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "7NcAllaEKsJj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#shameonyou           1\n",
       "shop                  1\n",
       "advantage             1\n",
       "#coronavirus          1\n",
       "taking                1\n",
       "disproportionately    1\n",
       "suffer                1\n",
       "can't                 1\n",
       "keepers               1\n",
       "prices                1\n",
       "marginalised          1\n",
       "#wewillremember       1\n",
       "afford                1\n",
       "boosting              1\n",
       "interrupted           0\n",
       "interruptions         0\n",
       "interrupters          0\n",
       "interruption          0\n",
       "###covid-19           0\n",
       "intersection          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = cv.transform([df.iloc[ind]['OriginalTweet']]).toarray()\n",
    "bof = pd.Series(arr.reshape(-1), index=cv.get_feature_names_out())\n",
    "bof = bof.sort_values(ascending=False)\n",
    "bof.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpEsl1k_NF4T"
   },
   "source": [
    "**Ответ:** самых важных слово в тексте - 11, ровно столько в нем токенов.\n",
    "То есть каждое слово имеет одинаковый вес в данном представлении. То есть мы не смогли отпределить самого важногог токена."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4DsEQpLO3J6"
   },
   "source": [
    "Теперь примените TfidfVectorizer и  определите самый важный/неважный токены. Хорошо ли определились, почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "uSNzdK3ENGB3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marginalised          0.372229\n",
       "#wewillremember       0.372229\n",
       "#shameonyou           0.357672\n",
       "disproportionately    0.332786\n",
       "keepers               0.322457\n",
       "boosting              0.305027\n",
       "suffer                0.273826\n",
       "afford                0.226760\n",
       "advantage             0.210476\n",
       "can't                 0.195721\n",
       "taking                0.185294\n",
       "shop                  0.171499\n",
       "prices                0.096851\n",
       "#coronavirus          0.071150\n",
       "dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
    "tfidf_vec.fit(X_train[\"OriginalTweet\"])\n",
    "\n",
    "ans = tfidf_vec.transform([df.iloc[ind]['OriginalTweet']]).toarray()\n",
    "\n",
    "needed_indexes = custom_tokenizer(df.iloc[ind]['OriginalTweet'])\n",
    "\n",
    "sample_v = pd.Series(ans.reshape(-1), index=tfidf_vec.get_feature_names_out())\n",
    "sample_v = sample_v.reindex(needed_indexes)\n",
    "sample_v = sample_v.sort_values(ascending=False)\n",
    "sample_v.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYao_UhqQADm"
   },
   "source": [
    "**Ответ:**\n",
    "\n",
    "Маргинализировать в самом деле обычно имеет негативную окраску как что-то непопулярное и отталкивающие массы. Так что браво! Да и весь топ-3 (который очень похож по важности) сильно передает негативную окраску текстов. \n",
    "\n",
    "И последнему месту браво не меньше, ведь коронавирус упоминаются в таком большом количестве твитов, что на этот токен не имеет смысла ориентироваться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGRJPqfWSesQ"
   },
   "source": [
    "Найдите какой-нибудь положительно окрашенный твитт, где TfidfVectorizer хорошо (полезно для определения окраски) выделяет важный токен, поясните пример.\n",
    "\n",
    "*Подсказка:* явно положительные твитты можно искать при помощи положительных слов (good, great, amazing и т. д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "jSjbKPCWk87K"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"On the way home, I wanted to stop by a grocery store for a few items but I didn't. It can wait. I hope my decision today saved a life or two! #DidntDoList #StayHomeSaveLives\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 33169\n",
    "\n",
    "# в предложении есть слово \"hope\"\n",
    "sample = df.iloc[idx]\n",
    "sample[\"OriginalTweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#didntdolist          0.444726\n",
       "saved                 0.341868\n",
       "decision              0.306653\n",
       "wanted                0.289260\n",
       "wait                  0.266668\n",
       "#stayhomesavelives    0.245920\n",
       "hope                  0.233062\n",
       "life                  0.232755\n",
       "two                   0.223306\n",
       "items                 0.207798\n",
       "way                   0.205628\n",
       "stop                  0.191945\n",
       "today                 0.189251\n",
       "home                  0.168751\n",
       "grocery               0.126756\n",
       "store                 0.122579\n",
       "dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_indexes = custom_tokenizer(df.iloc[idx]['OriginalTweet'])\n",
    "\n",
    "ans = tfidf_vec.transform([df.iloc[idx]['OriginalTweet']]).toarray()\n",
    "\n",
    "sample_v = pd.Series(ans.reshape(-1), index=tfidf_vec.get_feature_names_out())\n",
    "sample_v = sample_v.reindex(needed_indexes)\n",
    "sample_v = sample_v.sort_values(ascending=False)\n",
    "sample_v.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTv9ST2_U6NA"
   },
   "source": [
    "**Ответ:** Сравнивая мое предположительный токен: `hope`, и токен, выделенный\n",
    "алгоритмом, я склоняюсь к его версии! `saved` сразу навеевает позитив на сообщение. А что значит `#didntdolist` я так и не понял "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVEuZm8BHms6"
   },
   "source": [
    "## Задание 4 Обучение первых моделей (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JADkO3sfXdOG"
   },
   "source": [
    "Примените оба векторайзера для получения матриц с признаками текстов.  Выделите целевую переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "DguoiXhCX2oN"
   },
   "outputs": [],
   "source": [
    "simple_cv_train = cv.transform(X_train['OriginalTweet'])\n",
    "tfidf_vc_train = tfidf_vec.transform(X_train['OriginalTweet'])\n",
    "\n",
    "simple_cv_test = cv.transform(X_test['OriginalTweet'])\n",
    "tfidf_vc_test = tfidf_vec.transform(X_test['OriginalTweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FX1KSOfYSx4"
   },
   "source": [
    "Обучите логистическую регрессию на векторах из обоих векторайзеров. Посчитайте долю правильных ответов на обучающих и тестовых данных. Какой векторайзер показал лучший результат? Что можно сказать о моделях?\n",
    "\n",
    "Используйте `sparse` матрицы (после векторизации), не превращайте их в `numpy.ndarray` или `pd.DataFrame` - может не хватить памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "-Tb3eh8UXJ6v"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_train    0.984195\n",
       "count_test     0.870540\n",
       "tfidf_train    0.924306\n",
       "tfidf_test     0.850807\n",
       "dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_simple = LogisticRegression()\n",
    "lr_tfidf = LogisticRegression()\n",
    "\n",
    "lr_simple.fit(simple_cv_train, y_train)\n",
    "lr_tfidf.fit(tfidf_vc_train, y_train)\n",
    "\n",
    "simple_cv_train_pred = lr_simple.predict(simple_cv_train)\n",
    "tfidf_cv_train_pred = lr_tfidf.predict(tfidf_vc_train)\n",
    "\n",
    "simple_cv_test_pred = lr_simple.predict(simple_cv_test)\n",
    "tfidf_cv_test_pred = lr_tfidf.predict(tfidf_vc_test)\n",
    "\n",
    "data_accuracy = {\n",
    "    \"count_train\": accuracy_score(simple_cv_train_pred, y_train),\n",
    "    \"count_test\": accuracy_score(simple_cv_test_pred, y_test),\n",
    "    \"tfidf_train\": accuracy_score(tfidf_cv_train_pred, y_train),\n",
    "    \"tfidf_test\": accuracy_score(tfidf_cv_test_pred, y_test),\n",
    "}\n",
    "\n",
    "pd.Series(data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8y_wO7rCmv7K"
   },
   "source": [
    "**Ответ:** на наших моделях себя лучше показал логистический регрессор,\n",
    "и на `test`, и на `train` выборках. Получается, на данном примере себя намного лучше показал вариант векторизации попроще. Интерпретирвоать это сложно, на самом деле, но поптаюсь:\n",
    "\n",
    "ладно, я не знаю, сдаюсь..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSOR1i3mjrys"
   },
   "source": [
    "## Задание 5 Стемминг (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6ONBWNPjuq-"
   },
   "source": [
    "Для уменьшения словаря можно использовать стемминг.\n",
    "\n",
    "Модифицируйте написанный токенайзер, добавив в него стемминг с использованием SnowballStemmer. Обучите Count- и Tfidf- векторайзеры. Как изменился размер словаря?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "oVfA2-iMkQBb"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "st_l = st_w + list(punctuation)\n",
    "\n",
    "def custom_stem_tokenizer(text):\n",
    "    tokens = []\n",
    "    ts = tokenizer.tokenize(text)\n",
    "    ts = [stemmer.stem(t) for t in ts]\n",
    "    \n",
    "    for t in ts:\n",
    "        t = t.lower().strip()\n",
    "        \n",
    "        if len(t) == 1 and ord(t) >= 128:\n",
    "            continue\n",
    "        if len(re.findall(url_pattern, t)) > 0:\n",
    "            continue\n",
    "        if t in st_l:\n",
    "            continue\n",
    "\n",
    "        tokens.append(t)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QmrjYtqnlPd",
    "outputId": "cd91291d-9676-4611-9fc4-28afaed58963"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sampl', 'text', '@sample_text', '#sampletext', 'ad', 'word', 'check', 'stem']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_stem_tokenizer('This is sample text!!!! @Sample_text I, \\x92\\x92 https://t.co/sample  #sampletext adding more words to check stemming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zAvUTmaplzOS",
    "outputId": "566207fe-183b-4ed6-d333-f86f0cc9ae38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36662\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(tokenizer=custom_stem_tokenizer)\n",
    "cv.fit(X_train[\"OriginalTweet\"])\n",
    "\n",
    "print(len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyzs5TaAoHP6"
   },
   "source": [
    "**Ответ** Что предсказуемо, словарных запас значительно сохранился, ведь \n",
    "функция стемминга от невозрастающая (слов станосится меньше или равно). А так как наш корпус текстов был велик, он уменьшился."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OkncHI8oRmd"
   },
   "source": [
    "Обучите логистическую регрессию с использованием обоих векторайзеров. Изменилось ли качество? Есть ли смысл применять стемминг?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vc_stemed = CountVectorizer(tokenizer=custom_stem_tokenizer)\n",
    "tfidf_vc_stemed = TfidfVectorizer(tokenizer=custom_stem_tokenizer)\n",
    "\n",
    "count_vc_stemed.fit(X_train[\"OriginalTweet\"])\n",
    "tfidf_vc_stemed.fit(X_train[\"OriginalTweet\"])\n",
    "\n",
    "count_vc_test = count_vc_stemed.transform(X_test[\"OriginalTweet\"])\n",
    "count_vc_train = count_vc_stemed.transform(X_train[\"OriginalTweet\"])\n",
    "\n",
    "tfidf_vc_test = tfidf_vc_stemed.transform(X_test[\"OriginalTweet\"])\n",
    "tfidf_vc_train = tfidf_vc_stemed.transform(X_train[\"OriginalTweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "ykZJPphEoZ5W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_train    0.971038\n",
       "count_test     0.868846\n",
       "tfidf_train    0.916104\n",
       "tfidf_test     0.855990\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_count = LogisticRegression()\n",
    "lr_tfidf = LogisticRegression()\n",
    "\n",
    "lr_count.fit(count_vc_train, y_train)\n",
    "lr_tfidf.fit(tfidf_vc_train, y_train)\n",
    "\n",
    "count_train_pred = lr_count.predict(count_vc_train)\n",
    "tfidf_train_pred = lr_tfidf.predict(tfidf_vc_train)\n",
    "\n",
    "count_test_pred = lr_count.predict(count_vc_test)\n",
    "tfidf_test_pred = lr_tfidf.predict(tfidf_vc_test)\n",
    "\n",
    "data_stem_accuracy = {\n",
    "    \"count_train\": accuracy_score(count_train_pred, y_train),\n",
    "    \"count_test\": accuracy_score(count_test_pred, y_test),\n",
    "    \"tfidf_train\": accuracy_score(tfidf_train_pred, y_train),\n",
    "    \"tfidf_test\": accuracy_score(tfidf_test_pred, y_test),\n",
    "}\n",
    "\n",
    "pd.Series(data_stem_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCRlrODro0h8"
   },
   "source": [
    "**Ответ:** применив стеминг значения при `CountVectorizer` почти не изменились\n",
    "(что даже похоже на ошибку, но вроде нет), и `TfidfVectirizer` изменился несущественно: минус процент на обучающей, плюс процент на тестовой. В данно мпримере нет смсла использовать стемминг. Качество моделей меняется несущественно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYWGQNEDqLC-"
   },
   "source": [
    "## Задание  6 Работа с частотами (1.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Hq-tl5mqUSn"
   },
   "source": [
    "Еще один способ уменьшить количество признаков - это использовать параметры min_df и max_df при построении векторайзера  эти параметры помогают ограничить требуемую частоту встречаемости токена в документах.\n",
    "\n",
    "По умолчанию берутся все токены, которые встретились хотя бы один раз.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1SiD4DE3WZ2"
   },
   "source": [
    "Подберите max_df такой, что размер словаря будет 36651 (на 1 меньше, чем было). Почему параметр получился такой большой/маленький?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "tyEpkJUkjnuK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36650 0.1\n",
      "36661 0.325\n",
      "36662 0.55\n",
      "36662 0.775\n",
      "36662 1.0\n"
     ]
    }
   ],
   "source": [
    "possible = np.linspace(0.1, 1, 5)\n",
    "for p in possible:\n",
    "    cv_df = CountVectorizer(tokenizer=custom_stem_tokenizer,\n",
    "                        max_df=p\n",
    "                        ).fit(\n",
    "                            X_train[\"OriginalTweet\"]\n",
    "                            )\n",
    "    print(len(cv_df.vocabulary_), p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdZYoGZR4UsA"
   },
   "source": [
    "**Ответ:** получается, только 2 слова встречались в более чем 10% текстов,\n",
    "и только одно в более чем  в 32.5% текстов. Значение в ответ - 0.325, так как оно вычеркивает одно значение из текста.\n",
    "\n",
    "Это можно интерпретировать так: люди редко используют одни и те же слова (токены) (не считая мусорные stop-words), когда пишут посты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gRIUaB1u32f"
   },
   "source": [
    "Подберите min_df (используйте дефолтное значение max_df) в CountVectorizer таким образом, чтобы размер словаря был 3700 токенов (при использовании токенайзера со стеммингом), а качество осталось таким же, как и было. Что можно сказать о результатах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "mvMDwpdfjm8Y"
   },
   "outputs": [],
   "source": [
    "def din_search(l, r, res):\n",
    "    eps = 1e-10\n",
    "    while (r - l) > eps:\n",
    "        mid = (l + r) / 2\n",
    "        \n",
    "        cv_df = CountVectorizer(tokenizer=custom_stem_tokenizer,\n",
    "                        min_df=mid\n",
    "                        ).fit(\n",
    "                            X_train[\"OriginalTweet\"]\n",
    "                            )\n",
    "        cur_amount = len(cv_df.vocabulary_)\n",
    "\n",
    "        print(cur_amount, l, r)\n",
    "\n",
    "        if cur_amount < res: # то есть слов у нас мало, надо больше слов! надо уменьшить границу\n",
    "            r = mid\n",
    "        elif cur_amount == 3700:\n",
    "            return mid\n",
    "        else:\n",
    "            l = mid\n",
    "        \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 0.0001 0.1\n",
      "104 0.0001 0.050050000000000004\n",
      "244 0.0001 0.025075000000000004\n",
      "523 0.0001 0.012587500000000001\n",
      "974 0.0001 0.00634375\n",
      "1620 0.0001 0.0032218750000000003\n",
      "2436 0.0001 0.0016609375\n",
      "3513 0.0001 0.0008804687500000001\n",
      "5006 0.0001 0.000490234375\n",
      "3933 0.0002951171875 0.000490234375\n",
      "3698 0.00039267578125 0.000490234375\n",
      "3933 0.00039267578125 0.000441455078125\n",
      "3698 0.0004170654296875 0.000441455078125\n",
      "3933 0.0004170654296875 0.00042926025390624997\n",
      "3933 0.000423162841796875 0.00042926025390624997\n",
      "3698 0.00042621154785156247 0.00042926025390624997\n",
      "3933 0.00042621154785156247 0.00042773590087890625\n",
      "3698 0.00042697372436523433 0.00042773590087890625\n",
      "3933 0.00042697372436523433 0.0004273548126220703\n",
      "3698 0.0004271642684936523 0.0004273548126220703\n",
      "3698 0.0004271642684936523 0.0004272595405578613\n",
      "3698 0.0004271642684936523 0.0004272119045257568\n",
      "3698 0.0004271642684936523 0.00042718808650970457\n",
      "3698 0.0004271642684936523 0.0004271761775016784\n",
      "3933 0.0004271642684936523 0.00042717022299766535\n",
      "3698 0.00042716724574565885 0.00042717022299766535\n",
      "3698 0.00042716724574565885 0.00042716873437166213\n",
      "3933 0.00042716724574565885 0.0004271679900586605\n",
      "3933 0.00042716761790215967 0.0004271679900586605\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m din_search(\u001b[38;5;241m0.0001\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m3700\u001b[39m)\n",
      "Cell \u001b[0;32mIn[161], line 8\u001b[0m, in \u001b[0;36mdin_search\u001b[0;34m(l, r, res)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (r \u001b[38;5;241m-\u001b[39m l) \u001b[38;5;241m>\u001b[39m eps:\n\u001b[1;32m      4\u001b[0m     mid \u001b[38;5;241m=\u001b[39m (l \u001b[38;5;241m+\u001b[39m r) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      6\u001b[0m     cv_df \u001b[38;5;241m=\u001b[39m CountVectorizer(tokenizer\u001b[38;5;241m=\u001b[39mcustom_stem_tokenizer,\n\u001b[1;32m      7\u001b[0m                     min_df\u001b[38;5;241m=\u001b[39mmid\n\u001b[0;32m----> 8\u001b[0m                     )\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      9\u001b[0m                         X_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginalTweet\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m                         )\n\u001b[1;32m     11\u001b[0m     cur_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(cv_df\u001b[38;5;241m.\u001b[39mvocabulary_)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(cur_amount, l, r)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1323\u001b[0m, in \u001b[0;36mCountVectorizer.fit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, raw_documents, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Learn a vocabulary dictionary of all tokens in the raw documents.\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \n\u001b[1;32m   1310\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;124;03m        Fitted vectorizer.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1369\u001b[0m             )\n\u001b[1;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1259\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1258\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m analyze(doc):\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:110\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    108\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[129], line 13\u001b[0m, in \u001b[0;36mcustom_stem_tokenizer\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     11\u001b[0m tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m ts \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n\u001b[0;32m---> 13\u001b[0m ts \u001b[38;5;241m=\u001b[39m [stemmer\u001b[38;5;241m.\u001b[39mstem(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ts]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ts:\n\u001b[1;32m     16\u001b[0m     t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/nltk/stem/snowball.py:1431\u001b[0m, in \u001b[0;36mEnglishStemmer.stem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     word \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, word[\u001b[38;5;241m1\u001b[39m:]))\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(word)):\n\u001b[0;32m-> 1431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__vowels \u001b[38;5;129;01mand\u001b[39;00m word[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1432\u001b[0m         word \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((word[:i], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, word[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :]))\n\u001b[1;32m   1434\u001b[0m step1a_vowel_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "din_search(0.0001, 0.1, 3700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fGYpUIZx0fk"
   },
   "source": [
    "**Ответ:** получатся, четку грань найти сложно, однако число \n",
    "`0.0004271679900586605` наиболее подходит под условие задачи.\n",
    "\n",
    "Интерпретация: всего доли процента достаточно, чтобы отрезать большую часть слов (токенов). То есть слова редко встрнечаются в разных текстах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_db_var = 0.0004271679900586605"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx_h_-inKbBl"
   },
   "source": [
    "В предыдущих заданиях признаки не скалировались. Отскалируйте данные (при словаре размера 3.7 тысяч, векторизованные CountVectorizer), обучите логистическую регрессию, посмотрите качество и выведите `barplot`, содержащий по 10 токенов, с наибольшим по модулю положительными/отрицательными весами. Что можно сказать об этих токенах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "KBATXJX6LG9q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    0.942161\n",
       "test     0.835758\n",
       "dtype: float64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "count_vc_data = CountVectorizer(\n",
    "    tokenizer=custom_stem_tokenizer,\n",
    "    min_df=min_db_var\n",
    ")\n",
    "\n",
    "train = count_vc_data.fit_transform(X_train[\"OriginalTweet\"])\n",
    "test = count_vc_data.transform(X_test[\"OriginalTweet\"])\n",
    "\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(train)\n",
    "train_normed = sc.transform(train)\n",
    "test_normed = sc.transform(test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_normed, y_train)\n",
    "\n",
    "train_pred = lr.predict(train_normed)\n",
    "test_pred = lr.predict(test_normed)\n",
    "\n",
    "accuracy = {\n",
    "    \"train\": accuracy_score(train_pred, y_train),\n",
    "    \"test\": accuracy_score(test_pred, y_test)\n",
    "}\n",
    "\n",
    "data_ans = pd.Series(accuracy)\n",
    "data_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crisi   -1.803679\n",
       "panic   -1.358317\n",
       "scam    -1.157640\n",
       "kill    -0.712733\n",
       "war     -0.650703\n",
       "           ...   \n",
       "best     0.936242\n",
       "thank    0.965898\n",
       "free     0.986654\n",
       "help     1.103822\n",
       "hand     1.133040\n",
       "Length: 3698, dtype: float64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_weigth = pd.Series(\n",
    "    data=lr.coef_[0],\n",
    "    index=count_vc_data.get_feature_names_out()\n",
    ")\n",
    "tokens_weigth = tokens_weigth.sort_values()\n",
    "tokens_weigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14bf5a330>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "positive = tokens_weigth[tokens_weigth > 0]\n",
    "negative = tokens_weigth[tokens_weigth < 0]\n",
    "\n",
    "top_5_positive = positive.iloc[-5:]\n",
    "top_5_negative = negative.iloc[:5]\n",
    "\n",
    "top_score = pd.DataFrame(\n",
    "    data=pd.concat([top_5_positive, top_5_negative]),\n",
    "    columns=[\"coef\"]\n",
    ")\n",
    "\n",
    "top_score[\"is_positive\"] = top_score[\"coef\"] > 0\n",
    "top_score[\"coef\"] = top_score[\"coef\"].abs()\n",
    "top_score = top_score.sort_values(\"coef\", ascending=False)\n",
    "\n",
    "blue_c = \"#162E65\"\n",
    "red_c = \"#B12D49\"\n",
    "color_bar = np.where(top_score[\"is_positive\"], blue_c, red_c)\n",
    "\n",
    "red_patch = mpatches.Patch(color=red_c, label='negative words')\n",
    "blue_patch = mpatches.Patch(color=blue_c, label='positive words')\n",
    "\n",
    "ax = top_score.plot.bar(y=\"coef\", color=color_bar, title=\"important words\")\n",
    "ax.legend(handles=[red_patch, blue_patch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThcEfzY1LHET"
   },
   "source": [
    "**Ответ:** Данные токены самые важные в процессе анализа и определения\n",
    "тональности текста. Все они в самом деле (по субъективному мнению) отображают позитивную или негативную окраску."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktJVOdrIHq7B"
   },
   "source": [
    "## Задание 7 Другие признаки (1.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yt3jRCZ2H0Og"
   },
   "source": [
    "Мы были сконцентрированы на работе с текстами твиттов и не использовали другие признаки - имена пользователя, дату и местоположение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52wjewCCo_di"
   },
   "source": [
    "Изучите признаки UserName и ScreenName. полезны ли они? Если полезны, то закодируйте их, добавьте к матрице с отскалированными признаками, обучите логистическую регрессию, замерьте качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63thouYZptj6"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8_qR-gnpT3a"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ythEcFSkt7y3"
   },
   "source": [
    "Изучите признак TweetAt в обучающей выборке: преобразуйте его к типу datetime и нарисуйте его гистограмму с разделением по цвету на основе целевой переменной. Полезен ли он? Если полезен, то закодируйте его, добавьте к матрице с отскалированными признаками, обучите логистическую регрессию, замерьте качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lxb_k0JLirNv"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IdLBdpQxM-G"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2JtRPhNP6qx"
   },
   "source": [
    "Поработайте с признаком Location в обучающей выборке. Сколько уникальных значений?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYQZQ1FRNpoe"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6k4JwpRTQISa"
   },
   "source": [
    "Постройте гистограмму топ-10 по популярности местоположений (исключая Unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J91YkhegJ0mz"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOsv3lODTfYB"
   },
   "source": [
    "Видно, что многие местоположения включают в себя более точное название места, чем другие (Например, у некоторых стоит London, UK; а у некоторых просто UK или United Kingdom).\n",
    "\n",
    "Создайте новый признак WiderLocation, который содержит самое широкое местоположение (например, из London, UK должно получиться UK). Сколько уникальных категорий теперь? Постройте аналогичную гистограмму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSkow6acOMyD"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgyWrD2eVfff"
   },
   "source": [
    "Закодируйте признак WiderLocation с помощью OHE таким образом, чтобы создались только столбцы для местоположений, которые встречаются более одного раза. Сколько таких значений?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeJBfBWgPvg_"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyMX5kZuimPK"
   },
   "source": [
    "Добавьте этот признак к матрице отскалированных текстовых признаков, обучите логистическую регрессию, замерьте качество. Как оно изменилось? Оказался ли признак полезным?\n",
    "\n",
    "\n",
    "*Подсказка:* используйте параметр `categories` в энкодере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EO1jNPeeim7A"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dHsGlDRYUQt"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
